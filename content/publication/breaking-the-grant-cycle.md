+++
title = "Breaking the grant cycle: On the rational allocation of public resources to scientific research projects"

# Date first published.
date = "2015-05-07"

# Authors. Comma separated list, e.g. `["Bob Smith", "David Jones"]`.
authors = ["Shahar Avin"]

# Publication type.
# Legend:
# 0 = Uncategorized
# 1 = Conference proceedings
# 2 = Journal
# 3 = Work in progress
# 4 = Technical report
# 5 = Book
# 6 = Book chapter
publication_types = ["0"]

# Publication name and optional abbreviated version.
publication = "PhD thesis."

# Abstract and optional shortened version.
abstract = "The thesis presents a reformative criticism of science funding by peer review. The criticism is based on epistemological scepticism, regarding the ability of scientific peers, or any other agent, to have access to sufficient information regarding the potential of proposed projects at the time of funding. The scepticism is based on the complexity of factors contributing to the merit of scientific projects, and the rate at which the parameters of this complex system change their values. By constructing models of different science funding mechanisms, a construction supported by historical evidence, computational simulations show that in a significant subset of cases it would be better to select research projects by a lottery mechanism than by selection based on peer review. This last result is used to create a template for an alternative funding mechanism that combines the merits of peer review with the benefits of random allocation, while noting that this alternative is not so far removed from current practice as may first appear."
short_abstract = "Agent-based simulations of hypothetical research communities show random allocation can outperform selection by potential merit under certain conditions."

# Featured image thumbnail (optional)
image_preview = ""

# Is this a selected publication? (true/false)
selected = false

# Projects (optional).
#   Associate this publication with one or more of your projects.
#   Simply enter the filename (excluding '.md') of your project file in `content/project/`.
#   E.g. `projects = ["deep-learning"]` references `content/project/deep-learning.md`.
projects = ["simulating-science-funding"]

# Links (optional).
url_pdf = "https://www.repository.cam.ac.uk/bitstream/handle/1810/247434/phd_dissertation_final_for_print.pdf?sequence=1&isAllowed=y"
url_preprint = ""
url_code = ""
url_dataset = ""
url_project = ""
url_slides = ""
url_video = ""
url_poster = "pdf/breaking-the-grant-cycle-poster.pdf"
url_source = ""

# Custom links (optional).
#   Uncomment line below to enable. For multiple links, use the form `[{...}, {...}, {...}]`.
# url_custom = [{name = "Custom Link", url = "http://example.org"}]

# Does the content use math formatting?
math = false

# Does the content use source code highlighting?
highlight = false

# Featured image
# Place your image in the `static/img/` folder and reference its filename below, e.g. `image = "example.jpg"`.
# [header]
# image = "headers/bubbles-wide.jpg"
# caption = "My caption ðŸ˜„"

tags = ["science funding"]

+++

No-one can assess
proposals better than peers,
but are they biased?

Science is more like
climbing mountains in a fog
than finding lost dogs.

We should fund science
that will make our lives better
eventually.

Each projectâ€™s impact
will be determined by a
complex causal mess.

Random selection
can outperform peer review
in simulations.

Let us be honest
about the random aspect
of science funding.
